knitr::opts_chunk$set(echo = TRUE)
# Seleccionar las variables predictoras
predictors <- c("MSSubClass", "LotFrontage", "LotArea", "OverallQual",
"OverallCond", "BsmtFinSF1", "1stFlrSF", "GrLivArea",
"BsmtFullBath", "FullBath", "HalfBath", "TotRmsAbvGrd",
"Fireplaces", "GarageCars", "GarageArea", "WoodDeckSF",
"OpenPorchSF", "EnclosedPorch", "ScreenPorch", "MoSold",
"YrSold")
# Construir el modelo de regresi칩n lineal
model <- lm(SalePrice ~ ., data = trainData[, c(predictors, "SalePrice")])
setwd("C:/Users/GAMING/Documents")
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
correlations <-
library(corrplot)
corr_matrix <- cor(trainData[, sapply(trainData, is.numeric)])
corrplot(corr_matrix, method = "color")
# Crear el conjunto de datos de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
# Definir las variables predictoras
predictors <- c("MSSubClass", "LotFrontage", "LotArea", "OverallQual", "OverallCond", "YearBuilt", "BsmtFinSF1", "1stFlrSF", "GrLivArea", "BsmtFullBath", "FullBath", "HalfBath", "TotRmsAbvGrd", "Fireplaces", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "ScreenPorch", "MoSold", "YrSold")
# Crear el modelo lineal
model <- lm(SalePrice ~ ., data = trainData[, c(predictors, "SalePrice")])
***Ejericicio 10 ***
train.names()
names(train)
names(trainData)
```{r}
names(trainData)
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
predictors <- names(trainData)[sapply(trainData, is.numeric)]
cor_matrix <- cor(trainData[, predictors])
corrplot(cor_matrix, method = "color")
# Cargar los datos y ajustar el modelo
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
predictors <- c("OverallQual", "GrLivArea", "GarageCars", "TotalBsmtSF", "FullBath", "YearBuilt")
lm.fit <- lm(SalePrice ~ ., data = trainData[, c(predictors, "SalePrice")])
# Graficar los residuos y modelo
par(mfrow = c(2, 2))
plot(lm.fit$residuals, pch = 20, main = "Residuals vs Fitted")
plot(lm.fit$fitted.values, lm.fit$residuals, pch = 20, main = "Residuals vs Fitted Values")
qqnorm(lm.fit$residuals, main = "Normal Q-Q Plot")
qqline(lm.fit$residuals)
hist(lm.fit$residuals, main = "Histogram of Residuals")
# Gr치fico del modelo y los datos de entrenamiento
plot(trainData$SalePrice ~ trainData$GrLivArea, col="blue", main="GrLivArea vs SalePrice")
abline(lm_model, col="red", lwd=2)
# Gr치fico del modelo y los datos de entrenamiento
plot(trainData$SalePrice ~ trainData$GrLivArea, col="blue", main="GrLivArea vs SalePrice")
abline(lm_model, col="red", lwd=2)
# Cargar los datos y preparar los datos de entrenamiento y prueba
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
# Crear el modelo de regresi칩n lineal y hacer predicciones en el conjunto de prueba
model <- lm(SalePrice ~ ., data = trainData)
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
predictors <- names(trainData)[sapply(trainData, is.numeric)]
cor_matrix <- cor(trainData[, predictors])
corrplot(cor_matrix, method = "color")
# Cargar los datos y ajustar el modelo
train <- read.csv("train.csv")
library(caret)
set.seed(123)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]
predictors <- c("OverallQual", "GrLivArea", "GarageCars", "TotalBsmtSF", "FullBath", "YearBuilt")
lm.fit <- lm(SalePrice ~ ., data = trainData[, c(predictors, "SalePrice")])
# Graficar los residuos
par(mfrow = c(2, 2))
plot(lm.fit$residuals, pch = 20, main = "Residuals vs Fitted")
plot(lm.fit$fitted.values, lm.fit$residuals, pch = 20, main = "Residuals vs Fitted Values")
qqnorm(lm.fit$residuals, main = "Normal Q-Q Plot")
qqline(lm.fit$residuals)
hist(lm.fit$residuals, main = "Histogram of Residuals")
predictions <- predict(lm_model, testData[, sapply(testData, is.numeric)])
predictions <- predict(lm_model, testData[, sapply(testData, is.numeric)])
load("~/Git/HDT6-ModeloRegresionLogistica/main.rmd")
setwd("C:/Users/GAMING/Documents/Git/HDT6-ModeloRegresionLogistica")
install.packages("mltools")
# AIC y BIC para modelo 1
AIC_modelo1 <- AIC(modelo)
